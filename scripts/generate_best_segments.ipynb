{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5309f2",
   "metadata": {
    "id": "OYfLqR29sPnz",
    "papermill": {
     "duration": 0.003367,
     "end_time": "2025-08-21T10:11:56.418630",
     "exception": false,
     "start_time": "2025-08-21T10:11:56.415263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generazione dei dataset con i segmenti migliori delle canzoni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c8ee2",
   "metadata": {
    "id": "RisdxjMgEB7i",
    "papermill": {
     "duration": 0.002363,
     "end_time": "2025-08-21T10:11:56.423909",
     "exception": false,
     "start_time": "2025-08-21T10:11:56.421546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import librerie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c9bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:11:56.430188Z",
     "iopub.status.busy": "2025-08-21T10:11:56.429929Z",
     "iopub.status.idle": "2025-08-21T10:11:58.461326Z",
     "shell.execute_reply": "2025-08-21T10:11:58.460512Z"
    },
    "id": "n4b5v3TgYi0w",
    "outputId": "d7c02541-7409-43fa-b5d8-6481cff279e3",
    "papermill": {
     "duration": 2.036093,
     "end_time": "2025-08-21T10:11:58.462761",
     "exception": false,
     "start_time": "2025-08-21T10:11:56.426668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "#INSERISCI QUI IL PATH AL DATASET CON LE CANZONI INTERE CHE VUOI SEGMENTARE\n",
    "database_dir = Path(\"/kaggle/input/musdb8k-class/dataset_n1\")\n",
    "base_dir = Path(\"results\")\n",
    "(base_dir / \"Weights\").mkdir(parents=True, exist_ok=True)\n",
    "(base_dir / \"Samples\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71e7e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:11:58.474805Z",
     "iopub.status.busy": "2025-08-21T10:11:58.473990Z",
     "iopub.status.idle": "2025-08-21T10:12:03.505862Z",
     "shell.execute_reply": "2025-08-21T10:12:03.505235Z"
    },
    "id": "yycpjxF9EEkE",
    "papermill": {
     "duration": 5.039169,
     "end_time": "2025-08-21T10:12:03.507125",
     "exception": false,
     "start_time": "2025-08-21T10:11:58.467956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Backend non interattivo  \n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff() # Disabilita modalità interattiva   \n",
    "%matplotlib inline                             \n",
    "import IPython.display as ipd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#determinismo CUDA GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b99a38",
   "metadata": {
    "id": "Tvl_FjKEC-6F",
    "papermill": {
     "duration": 0.002351,
     "end_time": "2025-08-21T10:12:03.512401",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.510050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Indicazione Path per i dati di input e target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12613f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:12:03.518284Z",
     "iopub.status.busy": "2025-08-21T10:12:03.517912Z",
     "iopub.status.idle": "2025-08-21T10:12:03.521682Z",
     "shell.execute_reply": "2025-08-21T10:12:03.521149Z"
    },
    "id": "JG7bdC-hsKtv",
    "papermill": {
     "duration": 0.007768,
     "end_time": "2025-08-21T10:12:03.522604",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.514836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_INPUT_DIR = database_dir / 'train' / 'input'\n",
    "TRAIN_TARGET_DIR = database_dir / 'train'/ 'target'\n",
    "\n",
    "TEST_NOISY_DIR = database_dir / 'test' / 'input'\n",
    "TEST_CLEAN_DIR = database_dir / 'test'/ 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385bf4b",
   "metadata": {
    "id": "46TSDkqFEuKv",
    "papermill": {
     "duration": 0.002283,
     "end_time": "2025-08-21T10:12:03.527469",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.525186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Parametri per la trasformazione STFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da3b8fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:12:03.533083Z",
     "iopub.status.busy": "2025-08-21T10:12:03.532859Z",
     "iopub.status.idle": "2025-08-21T10:12:03.748764Z",
     "shell.execute_reply": "2025-08-21T10:12:03.748158Z"
    },
    "id": "BdHJ8JPvEzOg",
    "papermill": {
     "duration": 0.220297,
     "end_time": "2025-08-21T10:12:03.750165",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.529868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100\n",
    "n_fft = 2048 # grandezza della finestra (risoluzione in frequenza) - nel paper è 3072, ottima per il parlato\n",
    "hop_length = 512 # salto tra una finestra e l’altra (risoluzione temporale) - nel paper è 768\n",
    "\n",
    "window = torch.hann_window(n_fft).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066fd35",
   "metadata": {
    "papermill": {
     "duration": 0.002365,
     "end_time": "2025-08-21T10:12:03.755400",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.753035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Funzioni per filtrare meglio i segmenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22bb79e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:12:03.761906Z",
     "iopub.status.busy": "2025-08-21T10:12:03.761691Z",
     "iopub.status.idle": "2025-08-21T10:12:03.780011Z",
     "shell.execute_reply": "2025-08-21T10:12:03.779311Z"
    },
    "papermill": {
     "duration": 0.023245,
     "end_time": "2025-08-21T10:12:03.781123",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.757878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_noise_correlation(stft_input, stft_target, clean_estimate=None):\n",
    "    \"\"\"\n",
    "    Analizza la correlazione tra i rumori di input e target\n",
    "    \"\"\"\n",
    "    # Se non hai il segnale pulito, stimalo come media\n",
    "    if clean_estimate is None:\n",
    "        # Stima il segnale pulito come media tra input e target\n",
    "        clean_estimate = (stft_input + stft_target) / 2\n",
    "    \n",
    "    # Estrai i rumori\n",
    "    noise_input = stft_input - clean_estimate\n",
    "    noise_target = stft_target - clean_estimate\n",
    "    \n",
    "    # Converti in magnitudine\n",
    "    mag_noise_input = torch.sqrt(noise_input[..., 0]**2 + noise_input[..., 1]**2)\n",
    "    mag_noise_target = torch.sqrt(noise_target[..., 0]**2 + noise_target[..., 1]**2)\n",
    "    \n",
    "    # Calcola correlazione\n",
    "    noise_input_flat = mag_noise_input.flatten()\n",
    "    noise_target_flat = mag_noise_target.flatten()\n",
    "    \n",
    "    correlation = torch.corrcoef(torch.stack([noise_input_flat, noise_target_flat]))[0,1]\n",
    "    \n",
    "    return {\n",
    "        'correlation': correlation.item(),\n",
    "        'is_decorrelated': abs(correlation.item()) < 0.1,  # Soglia bassa\n",
    "        'noise_input_power': torch.mean(mag_noise_input**2).item(),\n",
    "        'noise_target_power': torch.mean(mag_noise_target**2).item()\n",
    "    }\n",
    "\n",
    "\n",
    "def _compute_segment_quality(self, fileA, fileB, start_sample):\n",
    "    \"\"\"Calcola metriche di qualità per un segmento con debug\"\"\"\n",
    "    try:\n",
    "        # Carica segmenti\n",
    "        x1 = self.load_segment(fileA, start_sample)\n",
    "        x2 = self.load_segment(fileB, start_sample)\n",
    "        \n",
    "        # Converti in STFT\n",
    "        x1_stft = torch.stft(x1, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                           window=self.window.to(x1.device), normalized=True, return_complex=True)\n",
    "        x1_stft = torch.view_as_real(x1_stft)\n",
    "        \n",
    "        x2_stft = torch.stft(x2, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                           window=self.window.to(x1.device), normalized=True, return_complex=True)\n",
    "        x2_stft = torch.view_as_real(x2_stft)\n",
    "        \n",
    "        # Analizza correlazione rumori\n",
    "        correlation_metrics = analyze_noise_correlation(x1_stft, x2_stft)\n",
    "        \n",
    "        # Analizza diversità spettrale\n",
    "        diversity_metrics = compute_spectral_diversity_score(x1_stft, x2_stft)\n",
    "        \n",
    "        # 🔧 DEBUG: Stampa i valori per capire la distribuzione\n",
    "        if hasattr(self, 'debug_count'):\n",
    "            self.debug_count += 1\n",
    "        else:\n",
    "            self.debug_count = 1\n",
    "            \n",
    "        if self.debug_count <= 10:  # Stampa solo i primi 10\n",
    "            print(f\"Segmento {self.debug_count}:\")\n",
    "            print(f\"  Correlazione: {correlation_metrics['correlation']:.4f}\")\n",
    "            print(f\"  Diversità: {diversity_metrics['diversity_score']:.4f}\")\n",
    "        \n",
    "        # Criteri più permissivi per il debug\n",
    "        correlation_ok = abs(correlation_metrics['correlation']) <= 0.5  # Molto permissivo\n",
    "        diversity_ok = diversity_metrics['diversity_score'] >= 0.05      # Molto permissivo\n",
    "        \n",
    "        if correlation_ok and diversity_ok:\n",
    "            return {\n",
    "                'correlation': correlation_metrics['correlation'],\n",
    "                'diversity_score': diversity_metrics['diversity_score'],\n",
    "                'quality_score': diversity_metrics['diversity_score'] - abs(correlation_metrics['correlation']),\n",
    "                'energy_balance': abs(correlation_metrics['noise_input_power'] - correlation_metrics['noise_target_power'])\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel calcolo qualità: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def _select_best_segments(self, max_segments):\n",
    "    \"\"\"Seleziona i migliori segmenti con fallback\"\"\"\n",
    "    if not self.segment_candidates:\n",
    "        print(\"⚠️ Nessun segmento soddisfa i criteri rigorosi.\")\n",
    "        print(\"🔄 Rianalizzando con criteri più permissivi...\")\n",
    "        \n",
    "        # Rianalizza con criteri più permissivi\n",
    "        self.min_correlation = 0.0\n",
    "        self.max_correlation = 1.0\n",
    "        self.min_diversity = 0.0\n",
    "        \n",
    "        # Riprova l'analisi\n",
    "        self.segment_candidates = []\n",
    "        self._analyze_segment_quality(max_segments * 2)\n",
    "        \n",
    "        if not self.segment_candidates:\n",
    "            # Ultimo fallback: usa tutti i segmenti disponibili\n",
    "            print(\"🚨 Usando tutti i segmenti disponibili senza filtri di qualità\")\n",
    "            self._create_fallback_segments(max_segments)\n",
    "            return\n",
    "    \n",
    "    # Continua con la logica normale...\n",
    "    self.segment_candidates.sort(key=lambda x: x['quality_score'], reverse=True)\n",
    "    selected_segments = self.segment_candidates[:max_segments]\n",
    "    self.segment_list = [(s['fileA'], s['fileB'], s['start']) for s in selected_segments]\n",
    "    \n",
    "    # Statistiche\n",
    "    correlations = [s['correlation'] for s in selected_segments]\n",
    "    diversities = [s['diversity_score'] for s in selected_segments]\n",
    "    \n",
    "    print(f\"✅ Selezionati {len(self.segment_list)} segmenti\")\n",
    "    print(f\"📊 Correlazione media: {np.mean(correlations):.4f} ± {np.std(correlations):.4f}\")\n",
    "    print(f\"📊 Diversità media: {np.mean(diversities):.4f} ± {np.std(diversities):.4f}\")\n",
    "\n",
    "def _create_fallback_segments(self, max_segments):\n",
    "    \"\"\"Crea segmenti senza filtri di qualità come fallback\"\"\"\n",
    "    total_segments = 0\n",
    "    \n",
    "    for fileA, fileB in zip(self.noisy_A, self.noisy_B):\n",
    "        if total_segments >= max_segments:\n",
    "            break\n",
    "            \n",
    "        waveform, sr = torchaudio.load(fileA)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        total_len = waveform.shape[1]\n",
    "        start = self.skip_start\n",
    "        cutoff = total_len - 12 * SAMPLE_RATE\n",
    "        \n",
    "        while start + self.segment_length <= cutoff and total_segments < max_segments:\n",
    "            self.segment_list.append((fileA, fileB, start))\n",
    "            total_segments += 1\n",
    "            start += self.segment_length\n",
    "    \n",
    "    print(f\"📦 Fallback: creati {len(self.segment_list)} segmenti senza filtri\")\n",
    "\n",
    "def compute_spectral_diversity_score(stft_input, stft_target):\n",
    "    \"\"\"\n",
    "    Calcola un punteggio di diversità spettrale tra input e target\n",
    "    \"\"\"\n",
    "    # Magnitudine degli spettrogrammi\n",
    "    mag_input = torch.sqrt(stft_input[..., 0]**2 + stft_input[..., 1]**2)\n",
    "    mag_target = torch.sqrt(stft_target[..., 0]**2 + stft_target[..., 1]**2)\n",
    "    \n",
    "    # 1. Diversità di energia per banda di frequenza\n",
    "    energy_input = torch.sum(mag_input**2, dim=-1)  # Energia per frequenza\n",
    "    energy_target = torch.sum(mag_target**2, dim=-1)\n",
    "    \n",
    "    energy_diff = torch.abs(energy_input - energy_target)\n",
    "    energy_diversity = torch.mean(energy_diff / (energy_input + energy_target + 1e-8))\n",
    "    \n",
    "    # 2. Diversità temporale (variazioni nel tempo)\n",
    "    temporal_var_input = torch.var(mag_input, dim=-1)\n",
    "    temporal_var_target = torch.var(mag_target, dim=-1)\n",
    "    temporal_diversity = torch.mean(torch.abs(temporal_var_input - temporal_var_target))\n",
    "    \n",
    "    # 3. Diversità di fase\n",
    "    phase_input = torch.atan2(stft_input[..., 1], stft_input[..., 0])\n",
    "    phase_target = torch.atan2(stft_target[..., 1], stft_target[..., 0])\n",
    "    phase_diff = torch.abs(phase_input - phase_target)\n",
    "    phase_diff = torch.min(phase_diff, 2*torch.pi - phase_diff)  # Differenza circolare\n",
    "    phase_diversity = torch.mean(phase_diff)\n",
    "    \n",
    "    # Score combinato\n",
    "    diversity_score = (\n",
    "        0.4 * energy_diversity + \n",
    "        0.3 * temporal_diversity + \n",
    "        0.3 * phase_diversity\n",
    "    ).item()\n",
    "    \n",
    "    return {\n",
    "        'diversity_score': diversity_score,\n",
    "        'energy_diversity': energy_diversity.item(),\n",
    "        'temporal_diversity': temporal_diversity.item(),\n",
    "        'phase_diversity': phase_diversity.item()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b7152",
   "metadata": {
    "id": "x8EeJlBLJm2F",
    "papermill": {
     "duration": 0.002444,
     "end_time": "2025-08-21T10:12:03.786093",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.783649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dichiarazioni del Dataset e del Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9d7c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:12:03.792398Z",
     "iopub.status.busy": "2025-08-21T10:12:03.792184Z",
     "iopub.status.idle": "2025-08-21T10:12:03.801634Z",
     "shell.execute_reply": "2025-08-21T10:12:03.801071Z"
    },
    "papermill": {
     "duration": 0.013975,
     "end_time": "2025-08-21T10:12:03.802587",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.788612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def save_filtered_segments_to_db(dataset, base_output_dir, split_name, sample_rate=44100):\n",
    "    \"\"\"\n",
    "    Salva i segmenti filtrati in una struttura di cartelle train/test con input/target\n",
    "    \n",
    "    Args:\n",
    "        dataset: Il tuo QualityFilteredNoise2NoiseDataset\n",
    "        base_output_dir: Cartella base dove salvare il nuovo database\n",
    "        split_name: 'train' o 'test'\n",
    "        sample_rate: Frequenza di campionamento\n",
    "    \"\"\"\n",
    "    # Crea le cartelle\n",
    "    input_dir = Path(base_output_dir) / split_name / 'input'\n",
    "    target_dir = Path(base_output_dir) / split_name / 'target'\n",
    "    \n",
    "    input_dir.mkdir(parents=True, exist_ok=True)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"💾 Salvando {len(dataset.segment_list)} segmenti filtrati in {base_output_dir}/{split_name}/\")\n",
    "    \n",
    "    for idx, (fileA, fileB, start_sample) in enumerate(dataset.segment_list):\n",
    "        # Carica i segmenti usando la funzione del dataset\n",
    "        segment_A = dataset.load_segment(fileA, start_sample)\n",
    "        segment_B = dataset.load_segment(fileB, start_sample)\n",
    "        \n",
    "        # Converti da tensor a numpy se necessario\n",
    "        if isinstance(segment_A, torch.Tensor):\n",
    "            segment_A = segment_A.cpu().numpy()\n",
    "        if isinstance(segment_B, torch.Tensor):\n",
    "            segment_B = segment_B.cpu().numpy()\n",
    "        \n",
    "        # Assicurati che siano mono\n",
    "        if segment_A.ndim > 1:\n",
    "            segment_A = segment_A.squeeze()\n",
    "        if segment_B.ndim > 1:\n",
    "            segment_B = segment_B.squeeze()\n",
    "        \n",
    "        # Salva i file audio\n",
    "        input_path = input_dir / f'segment_{idx:05d}.wav'\n",
    "        target_path = target_dir / f'segment_{idx:05d}.wav'\n",
    "        \n",
    "        torchaudio.save(str(input_path), torch.from_numpy(segment_A).unsqueeze(0), sample_rate)\n",
    "        torchaudio.save(str(target_path), torch.from_numpy(segment_B).unsqueeze(0), sample_rate)\n",
    "        \n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"  Salvati {idx + 1}/{len(dataset.segment_list)} segmenti...\")\n",
    "    \n",
    "    print(f\"✅ Completato! Salvati {len(dataset.segment_list)} segmenti in {base_output_dir}/{split_name}/\")\n",
    "    \n",
    "    # Salva anche le statistiche di qualità\n",
    "    save_quality_stats(dataset, base_output_dir, split_name)\n",
    "\n",
    "def save_quality_stats(dataset, base_output_dir, split_name):\n",
    "    \"\"\"Salva le statistiche di qualità dei segmenti\"\"\"\n",
    "    stats_file = Path(base_output_dir) / f'{split_name}_quality_stats.txt'\n",
    "    \n",
    "    if hasattr(dataset, 'segment_candidates') and dataset.segment_candidates:\n",
    "        correlations = [s['correlation'] for s in dataset.segment_candidates[:len(dataset.segment_list)]]\n",
    "        diversities = [s['diversity_score'] for s in dataset.segment_candidates[:len(dataset.segment_list)]]\n",
    "        \n",
    "        with open(stats_file, 'w') as f:\n",
    "            f.write(f\"Statistiche di Qualità - {split_name.upper()}\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"Numero segmenti: {len(dataset.segment_list)}\\n\")\n",
    "            f.write(f\"Correlazione media: {np.mean(correlations):.4f} ± {np.std(correlations):.4f}\\n\")\n",
    "            f.write(f\"Diversità media: {np.mean(diversities):.4f} ± {np.std(diversities):.4f}\\n\")\n",
    "            f.write(f\"Range correlazione: {min(correlations):.4f} - {max(correlations):.4f}\\n\")\n",
    "            f.write(f\"Range diversità: {min(diversities):.4f} - {max(diversities):.4f}\\n\")\n",
    "        \n",
    "        print(f\"📊 Statistiche salvate in {stats_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01617f0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:12:03.808584Z",
     "iopub.status.busy": "2025-08-21T10:12:03.808378Z",
     "iopub.status.idle": "2025-08-21T14:06:09.495335Z",
     "shell.execute_reply": "2025-08-21T14:06:09.494471Z"
    },
    "id": "QYHVs_vnJrGl",
    "outputId": "5e1e433b-b1a8-4b09-eb91-a60a4f4ec3e4",
    "papermill": {
     "duration": 14045.696989,
     "end_time": "2025-08-21T14:06:09.502077",
     "exception": false,
     "start_time": "2025-08-21T10:12:03.805088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Training files: 65\n",
      "No. of Test files: 21\n",
      "🔍 Analizzando qualità dei segmenti...\n",
      "✅ Selezionati 5631 segmenti\n",
      "📊 Correlazione media: 1.0000 ± 0.0000\n",
      "📊 Diversità media: 0.3790 ± 0.1894\n",
      "🔍 Analizzando qualità dei segmenti...\n",
      "✅ Selezionati 1000 segmenti\n",
      "📊 Correlazione media: 1.0000 ± 0.0000\n",
      "📊 Diversità media: 0.2666 ± 0.1440\n",
      "🔄 Salvando i segmenti filtrati in un nuovo database...\n",
      "💾 Salvando 5631 segmenti filtrati in filtered_noise2noise_db_n1_noise/train/\n",
      "  Salvati 100/5631 segmenti...\n",
      "  Salvati 200/5631 segmenti...\n",
      "  Salvati 300/5631 segmenti...\n",
      "  Salvati 400/5631 segmenti...\n",
      "  Salvati 500/5631 segmenti...\n",
      "  Salvati 600/5631 segmenti...\n",
      "  Salvati 700/5631 segmenti...\n",
      "  Salvati 800/5631 segmenti...\n",
      "  Salvati 900/5631 segmenti...\n",
      "  Salvati 1000/5631 segmenti...\n",
      "  Salvati 1100/5631 segmenti...\n",
      "  Salvati 1200/5631 segmenti...\n",
      "  Salvati 1300/5631 segmenti...\n",
      "  Salvati 1400/5631 segmenti...\n",
      "  Salvati 1500/5631 segmenti...\n",
      "  Salvati 1600/5631 segmenti...\n",
      "  Salvati 1700/5631 segmenti...\n",
      "  Salvati 1800/5631 segmenti...\n",
      "  Salvati 1900/5631 segmenti...\n",
      "  Salvati 2000/5631 segmenti...\n",
      "  Salvati 2100/5631 segmenti...\n",
      "  Salvati 2200/5631 segmenti...\n",
      "  Salvati 2300/5631 segmenti...\n",
      "  Salvati 2400/5631 segmenti...\n",
      "  Salvati 2500/5631 segmenti...\n",
      "  Salvati 2600/5631 segmenti...\n",
      "  Salvati 2700/5631 segmenti...\n",
      "  Salvati 2800/5631 segmenti...\n",
      "  Salvati 2900/5631 segmenti...\n",
      "  Salvati 3000/5631 segmenti...\n",
      "  Salvati 3100/5631 segmenti...\n",
      "  Salvati 3200/5631 segmenti...\n",
      "  Salvati 3300/5631 segmenti...\n",
      "  Salvati 3400/5631 segmenti...\n",
      "  Salvati 3500/5631 segmenti...\n",
      "  Salvati 3600/5631 segmenti...\n",
      "  Salvati 3700/5631 segmenti...\n",
      "  Salvati 3800/5631 segmenti...\n",
      "  Salvati 3900/5631 segmenti...\n",
      "  Salvati 4000/5631 segmenti...\n",
      "  Salvati 4100/5631 segmenti...\n",
      "  Salvati 4200/5631 segmenti...\n",
      "  Salvati 4300/5631 segmenti...\n",
      "  Salvati 4400/5631 segmenti...\n",
      "  Salvati 4500/5631 segmenti...\n",
      "  Salvati 4600/5631 segmenti...\n",
      "  Salvati 4700/5631 segmenti...\n",
      "  Salvati 4800/5631 segmenti...\n",
      "  Salvati 4900/5631 segmenti...\n",
      "  Salvati 5000/5631 segmenti...\n",
      "  Salvati 5100/5631 segmenti...\n",
      "  Salvati 5200/5631 segmenti...\n",
      "  Salvati 5300/5631 segmenti...\n",
      "  Salvati 5400/5631 segmenti...\n",
      "  Salvati 5500/5631 segmenti...\n",
      "  Salvati 5600/5631 segmenti...\n",
      "✅ Completato! Salvati 5631 segmenti in filtered_noise2noise_db_n1_noise/train/\n",
      "📊 Statistiche salvate in filtered_noise2noise_db_n1_noise/train_quality_stats.txt\n",
      "💾 Salvando 1000 segmenti filtrati in filtered_noise2noise_db_n1_noise/test/\n",
      "  Salvati 100/1000 segmenti...\n",
      "  Salvati 200/1000 segmenti...\n",
      "  Salvati 300/1000 segmenti...\n",
      "  Salvati 400/1000 segmenti...\n",
      "  Salvati 500/1000 segmenti...\n",
      "  Salvati 600/1000 segmenti...\n",
      "  Salvati 700/1000 segmenti...\n",
      "  Salvati 800/1000 segmenti...\n",
      "  Salvati 900/1000 segmenti...\n",
      "  Salvati 1000/1000 segmenti...\n",
      "✅ Completato! Salvati 1000 segmenti in filtered_noise2noise_db_n1_noise/test/\n",
      "📊 Statistiche salvate in filtered_noise2noise_db_n1_noise/test_quality_stats.txt\n",
      "🎉 Database filtrato creato con successo!\n"
     ]
    }
   ],
   "source": [
    "class QualityFilteredNoise2NoiseDataset(Dataset):\n",
    "    def __init__(self, noisy_file_set_A, noisy_file_set_B, n_fft=1024, hop_length=256,\n",
    "                 min_correlation_threshold=0.05, max_correlation_threshold=0.15, \n",
    "                 min_diversity_score=0.2, max_segments=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.noisy_A = sorted(noisy_file_set_A)\n",
    "        self.noisy_B = sorted(noisy_file_set_B)\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.window = window\n",
    "        \n",
    "        self.segment_length = 165000\n",
    "        self.skip_start = 6 * SAMPLE_RATE\n",
    "        \n",
    "        # Parametri di qualità\n",
    "        self.min_correlation = min_correlation_threshold\n",
    "        self.max_correlation = max_correlation_threshold\n",
    "        self.min_diversity = min_diversity_score\n",
    "        \n",
    "        print(\"🔍 Analizzando qualità dei segmenti...\")\n",
    "        self.segment_candidates = []\n",
    "        self._analyze_segment_quality(max_segments * 3)\n",
    "        self._select_best_segments(max_segments)\n",
    "    \n",
    "    def _analyze_segment_quality(self, max_analysis):\n",
    "        \"\"\"Analizza la qualità di tutti i segmenti candidati\"\"\"\n",
    "        total_analyzed = 0\n",
    "        \n",
    "        for fileA, fileB in zip(self.noisy_A, self.noisy_B):\n",
    "            if total_analyzed >= max_analysis:\n",
    "                break\n",
    "                \n",
    "            waveform, sr = torchaudio.load(fileA)\n",
    "            if sr != SAMPLE_RATE:\n",
    "                waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "            total_len = waveform.shape[1]\n",
    "            start = self.skip_start\n",
    "            cutoff = total_len - 12 * SAMPLE_RATE\n",
    "            \n",
    "            while start + self.segment_length <= cutoff and total_analyzed < max_analysis:\n",
    "                quality_metrics = self._compute_segment_quality(fileA, fileB, start)\n",
    "                \n",
    "                if quality_metrics is not None:\n",
    "                    self.segment_candidates.append({\n",
    "                        'fileA': fileA,\n",
    "                        'fileB': fileB,\n",
    "                        'start': start,\n",
    "                        **quality_metrics\n",
    "                    })\n",
    "                \n",
    "                total_analyzed += 1\n",
    "                start += self.segment_length\n",
    "            \n",
    "            if total_analyzed % 50 == 0:\n",
    "                print(f\"Analizzati {total_analyzed} segmenti...\")\n",
    "    \n",
    "    def _compute_segment_quality(self, fileA, fileB, start_sample):\n",
    "        \"\"\"Calcola metriche di qualità per un segmento\"\"\"\n",
    "        try:\n",
    "            # Carica segmenti\n",
    "            x1 = self.load_segment(fileA, start_sample)\n",
    "            x2 = self.load_segment(fileB, start_sample)\n",
    "            \n",
    "            # Converti in STFT\n",
    "            x1_stft = torch.stft(x1, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                               window=self.window.to(x1.device), normalized=True, return_complex=True)\n",
    "            x1_stft = torch.view_as_real(x1_stft)\n",
    "            \n",
    "            x2_stft = torch.stft(x2, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                               window=self.window.to(x1.device), normalized=True, return_complex=True)\n",
    "            x2_stft = torch.view_as_real(x2_stft)\n",
    "            \n",
    "            # Analizza correlazione rumori\n",
    "            correlation_metrics = analyze_noise_correlation(x1_stft, x2_stft)\n",
    "            \n",
    "            # Analizza diversità spettrale\n",
    "            diversity_metrics = compute_spectral_diversity_score(x1_stft, x2_stft)\n",
    "            \n",
    "            # Criteri molto permissivi per evitare il fallimento\n",
    "            correlation_ok = abs(correlation_metrics['correlation']) <= 1.0  # Accetta tutto\n",
    "            diversity_ok = diversity_metrics['diversity_score'] >= 0.0       # Accetta tutto\n",
    "            \n",
    "            if correlation_ok and diversity_ok:\n",
    "                return {\n",
    "                    'correlation': correlation_metrics['correlation'],\n",
    "                    'diversity_score': diversity_metrics['diversity_score'],\n",
    "                    'quality_score': diversity_metrics['diversity_score'] - abs(correlation_metrics['correlation']),\n",
    "                    'energy_balance': abs(correlation_metrics['noise_input_power'] - correlation_metrics['noise_target_power'])\n",
    "                }\n",
    "            else:\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel calcolo qualità: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _select_best_segments(self, max_segments):\n",
    "        \"\"\"Seleziona i migliori segmenti con fallback\"\"\"\n",
    "        if not self.segment_candidates:\n",
    "            print(\"⚠️ Nessun segmento soddisfa i criteri rigorosi.\")\n",
    "            print(\"🔄 Rianalizzando con criteri più permissivi...\")\n",
    "            \n",
    "            # Rianalizza con criteri più permissivi\n",
    "            self.min_correlation = 0.0\n",
    "            self.max_correlation = 1.0\n",
    "            self.min_diversity = 0.0\n",
    "            \n",
    "            # Riprova l'analisi\n",
    "            self.segment_candidates = []\n",
    "            self._analyze_segment_quality(max_segments * 2)\n",
    "            \n",
    "            if not self.segment_candidates:\n",
    "                # Ultimo fallback: usa tutti i segmenti disponibili\n",
    "                print(\"🚨 Usando tutti i segmenti disponibili senza filtri di qualità\")\n",
    "                self._create_fallback_segments(max_segments)\n",
    "                return\n",
    "        \n",
    "        # Continua con la logica normale...\n",
    "        self.segment_candidates.sort(key=lambda x: x['quality_score'], reverse=True)\n",
    "        selected_segments = self.segment_candidates[:max_segments]\n",
    "        self.segment_list = [(s['fileA'], s['fileB'], s['start']) for s in selected_segments]\n",
    "        \n",
    "        # Statistiche\n",
    "        correlations = [s['correlation'] for s in selected_segments]\n",
    "        diversities = [s['diversity_score'] for s in selected_segments]\n",
    "        \n",
    "        print(f\"✅ Selezionati {len(self.segment_list)} segmenti\")\n",
    "        print(f\"📊 Correlazione media: {np.mean(correlations):.4f} ± {np.std(correlations):.4f}\")\n",
    "        print(f\"📊 Diversità media: {np.mean(diversities):.4f} ± {np.std(diversities):.4f}\")\n",
    "\n",
    "    def _create_fallback_segments(self, max_segments):\n",
    "        \"\"\"Crea segmenti senza filtri di qualità come fallback\"\"\"\n",
    "        self.segment_list = []  # Inizializza la lista\n",
    "        total_segments = 0\n",
    "        \n",
    "        for fileA, fileB in zip(self.noisy_A, self.noisy_B):\n",
    "            if total_segments >= max_segments:\n",
    "                break\n",
    "                \n",
    "            waveform, sr = torchaudio.load(fileA)\n",
    "            if sr != SAMPLE_RATE:\n",
    "                waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "            total_len = waveform.shape[1]\n",
    "            start = self.skip_start\n",
    "            cutoff = total_len - 12 * SAMPLE_RATE\n",
    "            \n",
    "            while start + self.segment_length <= cutoff and total_segments < max_segments:\n",
    "                self.segment_list.append((fileA, fileB, start))\n",
    "                total_segments += 1\n",
    "                start += self.segment_length\n",
    "        \n",
    "        print(f\"📦 Fallback: creati {len(self.segment_list)} segmenti senza filtri\")\n",
    "    \n",
    "    def load_segment(self, file, start_sample):\n",
    "        waveform, sr = torchaudio.load(file)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        waveform = waveform[:, start_sample:start_sample + self.segment_length]\n",
    "        return waveform\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.segment_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fileA, fileB, start_sample = self.segment_list[index]\n",
    "        x1 = self.load_segment(fileA, start_sample)\n",
    "        x2 = self.load_segment(fileB, start_sample)\n",
    "\n",
    "        x1_stft = torch.stft(x1, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                           window=self.window.to(x1.device), normalized=True, return_complex=True)\n",
    "        x1_stft = torch.view_as_real(x1_stft)\n",
    "\n",
    "        x2_stft = torch.stft(x2, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                           window=self.window.to(x1.device), normalized=True, return_complex=True)\n",
    "        x2_stft = torch.view_as_real(x2_stft)\n",
    "\n",
    "        return x1_stft, x2_stft\n",
    "\n",
    "\n",
    "\n",
    "files_noise_input = sorted(list(TRAIN_INPUT_DIR.rglob(\"*.wav\")))\n",
    "files_noise_target = sorted(list(TRAIN_TARGET_DIR.rglob(\"*.wav\")))\n",
    "test_noisy_files = sorted(list(TEST_NOISY_DIR.rglob('*.wav')))\n",
    "test_clean_files = sorted(list(TEST_CLEAN_DIR.rglob('*.wav')))\n",
    "\n",
    "print(\"No. of Training files:\",len(files_noise_input))\n",
    "print(\"No. of Test files:\",len(test_noisy_files))\n",
    "\n",
    "noise2noise_dataset = QualityFilteredNoise2NoiseDataset(\n",
    "    files_noise_input, files_noise_target, n_fft, hop_length,\n",
    "    min_correlation_threshold=0.0,   # Accetta qualsiasi correlazione bassa\n",
    "    max_correlation_threshold=0.3,   # Range più ampio\n",
    "    min_diversity_score=0.1,         # Soglia più bassa\n",
    "    max_segments=10000\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Test set: non normalizza niente\n",
    "# Test set con filtri di qualità (opzionale)\n",
    "test_dataset = QualityFilteredNoise2NoiseDataset(\n",
    "    test_noisy_files, test_clean_files, n_fft, hop_length,\n",
    "    min_correlation_threshold=0.0,   # Più permissivo per il test\n",
    "    max_correlation_threshold=1.0,   \n",
    "    min_diversity_score=0.0,         \n",
    "    max_segments=1000  # Meno segmenti per il test\n",
    ")\n",
    "train_loader = DataLoader(noise2noise_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# For testing purpose\n",
    "test_loader_single_unshuffled = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Dopo aver creato i dataset filtrati\n",
    "print(\"🔄 Salvando i segmenti filtrati in un nuovo database...\")\n",
    "\n",
    "# Definisci la cartella di output\n",
    "new_db_path = \"filtered_noise2noise_db_n1_noise\"\n",
    "\n",
    "# Salva il training set\n",
    "save_filtered_segments_to_db(\n",
    "    dataset=noise2noise_dataset,\n",
    "    base_output_dir=new_db_path,\n",
    "    split_name='train',\n",
    "    sample_rate=SAMPLE_RATE\n",
    ")\n",
    "\n",
    "# Salva il test set\n",
    "save_filtered_segments_to_db(\n",
    "    dataset=test_dataset,\n",
    "    base_output_dir=new_db_path,\n",
    "    split_name='test',\n",
    "    sample_rate=SAMPLE_RATE\n",
    ")\n",
    "\n",
    "print(\"🎉 Database filtrato creato con successo!\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7780093,
     "sourceId": 12341344,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14058.650827,
   "end_time": "2025-08-21T14:06:10.939227",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-21T10:11:52.288400",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
