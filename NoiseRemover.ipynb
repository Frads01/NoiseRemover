{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYfLqR29sPnz",
    "papermill": {
     "duration": 0.008916,
     "end_time": "2025-08-11T17:51:18.898347",
     "exception": false,
     "start_time": "2025-08-11T17:51:18.889431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Noise Remover\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dataset di train e test devono essere già stati generati prima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RisdxjMgEB7i",
    "papermill": {
     "duration": 0.007174,
     "end_time": "2025-08-11T17:51:18.912953",
     "exception": false,
     "start_time": "2025-08-11T17:51:18.905779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import librerie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:21.117701Z",
     "iopub.status.busy": "2025-08-11T17:51:21.116902Z",
     "iopub.status.idle": "2025-08-11T17:51:25.535253Z",
     "shell.execute_reply": "2025-08-11T17:51:25.534582Z"
    },
    "id": "yycpjxF9EEkE",
    "papermill": {
     "duration": 4.427645,
     "end_time": "2025-08-11T17:51:25.536724",
     "exception": false,
     "start_time": "2025-08-11T17:51:21.109079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # backend per salvataggio file, no GUI \n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff() # Disabilita modalità interattiva     \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvl_FjKEC-6F",
    "papermill": {
     "duration": 0.007182,
     "end_time": "2025-08-11T17:51:25.552040",
     "exception": false,
     "start_time": "2025-08-11T17:51:25.544858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Indicazione Path per i dati di input e target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:25.568042Z",
     "iopub.status.busy": "2025-08-11T17:51:25.567262Z",
     "iopub.status.idle": "2025-08-11T17:51:25.571585Z",
     "shell.execute_reply": "2025-08-11T17:51:25.570770Z"
    },
    "id": "JG7bdC-hsKtv",
    "papermill": {
     "duration": 0.013395,
     "end_time": "2025-08-11T17:51:25.572754",
     "exception": false,
     "start_time": "2025-08-11T17:51:25.559359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INSERISCI QUI IL PATH AL DATASET CON LE CANZONI SEGMENTATE\n",
    "database_dir = Path(\"/kaggle/input/white-noise-def/filtered_noise2noise_db_white_noise\")\n",
    "base_dir = Path(\"results\")\n",
    "(base_dir / \"Weights\").mkdir(parents=True, exist_ok=True)\n",
    "(base_dir / \"Samples\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_INPUT_DIR = database_dir / 'train' / 'input'\n",
    "TRAIN_TARGET_DIR = database_dir / 'train'/ 'target'\n",
    "\n",
    "TEST_NOISY_DIR = database_dir / 'test' / 'input'\n",
    "TEST_CLEAN_DIR = database_dir / 'test'/ 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46TSDkqFEuKv",
    "papermill": {
     "duration": 0.007502,
     "end_time": "2025-08-11T17:51:25.587720",
     "exception": false,
     "start_time": "2025-08-11T17:51:25.580218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parametri per la trasformazione STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:25.603067Z",
     "iopub.status.busy": "2025-08-11T17:51:25.602800Z",
     "iopub.status.idle": "2025-08-11T17:51:25.808068Z",
     "shell.execute_reply": "2025-08-11T17:51:25.807441Z"
    },
    "id": "BdHJ8JPvEzOg",
    "papermill": {
     "duration": 0.214434,
     "end_time": "2025-08-11T17:51:25.809312",
     "exception": false,
     "start_time": "2025-08-11T17:51:25.594878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100\n",
    "n_fft = 2048 # grandezza della finestra (risoluzione in frequenza) - nel paper è 3072, ottima per il parlato\n",
    "hop_length = 512 # salto tra una finestra e l’altra (risoluzione temporale) - nel paper è 768\n",
    "\n",
    "window = torch.hann_window(n_fft).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8EeJlBLJm2F",
    "papermill": {
     "duration": 0.00666,
     "end_time": "2025-08-11T17:51:25.872573",
     "exception": false,
     "start_time": "2025-08-11T17:51:25.865913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dichiarazioni del Dataset e del Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:25.940355Z",
     "iopub.status.busy": "2025-08-11T17:51:25.940158Z",
     "iopub.status.idle": "2025-08-11T17:51:52.356367Z",
     "shell.execute_reply": "2025-08-11T17:51:52.355503Z"
    },
    "papermill": {
     "duration": 26.425429,
     "end_time": "2025-08-11T17:51:52.357608",
     "exception": false,
     "start_time": "2025-08-11T17:51:25.932179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNoise2NoiseDataset(Dataset):\n",
    "    def __init__(self, noisy_file_set_A, noisy_file_set_B, n_fft=1024, hop_length=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.noisy_A = sorted(noisy_file_set_A)\n",
    "        self.noisy_B = sorted(noisy_file_set_B)\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.window = window\n",
    "        \n",
    "        assert len(self.noisy_A) == len(self.noisy_B), \"Input e target devono avere lo stesso numero di file\"\n",
    "    \n",
    "    def load_audio_file(self, file_path):\n",
    "        \"\"\"Carica un file audio completo, rende mono e resample a SAMPLE_RATE\"\"\"\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        return waveform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.noisy_A)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fileA = self.noisy_A[index]\n",
    "        fileB = self.noisy_B[index]\n",
    "        \n",
    "        x1 = self.load_audio_file(fileA)\n",
    "        x2 = self.load_audio_file(fileB)\n",
    "\n",
    "        #Restituisce STFT complessa in formato real/imag\n",
    "        x1_stft = torch.stft(x1, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                           window=self.window.to(x1.device), normalized=True, return_complex=True)\n",
    "        x1_stft = torch.view_as_real(x1_stft)\n",
    "\n",
    "        x2_stft = torch.stft(x2, n_fft=self.n_fft, hop_length=self.hop_length,\n",
    "                           window=self.window.to(x1.device), normalized=True, return_complex=True)\n",
    "        x2_stft = torch.view_as_real(x2_stft)\n",
    "\n",
    "        return x1_stft, x2_stft\n",
    "\n",
    "\n",
    "files_noise_input = sorted(list(TRAIN_INPUT_DIR.rglob(\"*.wav\")))\n",
    "files_noise_target = sorted(list(TRAIN_TARGET_DIR.rglob(\"*.wav\")))\n",
    "test_noisy_files = sorted(list(TEST_NOISY_DIR.rglob('*.wav')))\n",
    "test_clean_files = sorted(list(TEST_CLEAN_DIR.rglob('*.wav')))\n",
    "\n",
    "print(\"Numero di segmenti per il train:\",len(files_noise_input))\n",
    "print(\"Numero di segmenti per il test:\",len(test_noisy_files))\n",
    "\n",
    "noise2noise_dataset = SimpleNoise2NoiseDataset(\n",
    "    files_noise_input, files_noise_target, n_fft, hop_length\n",
    ")\n",
    "\n",
    "test_dataset = SimpleNoise2NoiseDataset(\n",
    "    test_noisy_files, test_clean_files, n_fft, hop_length\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(noise2noise_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "test_loader_single_unshuffled = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHS5BTBuBTtz",
    "papermill": {
     "duration": 0.007437,
     "end_time": "2025-08-11T17:51:52.416824",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.409387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Definizione dei diversi layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWvdTgRc9NKh",
    "papermill": {
     "duration": 0.007155,
     "end_time": "2025-08-11T17:51:52.431619",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.424464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Layer convoluzionale per segnali complessi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.447941Z",
     "iopub.status.busy": "2025-08-11T17:51:52.447357Z",
     "iopub.status.idle": "2025-08-11T17:51:52.453745Z",
     "shell.execute_reply": "2025-08-11T17:51:52.453121Z"
    },
    "id": "2QgFF95s9XM1",
    "papermill": {
     "duration": 0.015867,
     "end_time": "2025-08-11T17:51:52.454901",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.439034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ComplexConv2d(nn.Module):  # convoluzione 2D su numeri complessi\n",
    "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "      super().__init__()\n",
    "\n",
    "      self.in_channels = in_channels\n",
    "      self.out_channels = out_channels\n",
    "      self.kernel_size = kernel_size\n",
    "      self.padding = padding\n",
    "      self.stride = stride\n",
    "\n",
    "      # crea una convoluzione per la parte reale:\n",
    "      self.real_conv = nn.Conv2d(in_channels=self.in_channels,\n",
    "                                 out_channels=self.out_channels,\n",
    "                                 kernel_size=self.kernel_size,\n",
    "                                 padding=self.padding,\n",
    "                                 stride=self.stride)\n",
    "\n",
    "      # crea un’altra convoluzione per la parte immaginaria.\n",
    "      # Nota: è separata, quindi ha i suoi pesi e bias distinti.\n",
    "      self.im_conv = nn.Conv2d(in_channels=self.in_channels,\n",
    "                               out_channels=self.out_channels,\n",
    "                               kernel_size=self.kernel_size,\n",
    "                               padding=self.padding,\n",
    "                               stride=self.stride)\n",
    "\n",
    "      # Glorot initialization.\n",
    "      nn.init.xavier_normal_(self.real_conv.weight)\n",
    "      nn.init.xavier_normal_(self.im_conv.weight)\n",
    "\n",
    "  def forward(self, x):  # x: è un tensore che contiene, sull’ultima dimensione, la parte reale e immaginaria\n",
    "        x_real = x[..., 0]\n",
    "        x_im = x[..., 1]\n",
    "\n",
    "        # calcolo convoluzione complessa\n",
    "        c_real = self.real_conv(x_real) - self.im_conv(x_im)\n",
    "        c_im = self.im_conv(x_real) + self.real_conv(x_im)\n",
    "\n",
    "        # combino le due parti (reale e immaginaria) di nuovo insieme, lungo l’ultima dimensione (dim = -1), per restituire un tensore complesso.\n",
    "        output = torch.stack([c_real, c_im], dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPG_oG9ZAytW",
    "papermill": {
     "duration": 0.064428,
     "end_time": "2025-08-11T17:51:52.527241",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.462813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Layer per deconvoluzione di segnali complessi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.545921Z",
     "iopub.status.busy": "2025-08-11T17:51:52.545243Z",
     "iopub.status.idle": "2025-08-11T17:51:52.551855Z",
     "shell.execute_reply": "2025-08-11T17:51:52.551105Z"
    },
    "id": "hwUoRLXXA5Op",
    "papermill": {
     "duration": 0.018047,
     "end_time": "2025-08-11T17:51:52.552975",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.534928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ComplexConvTranspose2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, output_padding=0, padding=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.output_padding = output_padding\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "        self.real_convt = nn.ConvTranspose2d(in_channels=self.in_channels,\n",
    "                                            out_channels=self.out_channels,\n",
    "                                            kernel_size=self.kernel_size,\n",
    "                                            output_padding=self.output_padding,\n",
    "                                            padding=self.padding,\n",
    "                                            stride=self.stride)\n",
    "\n",
    "        self.im_convt = nn.ConvTranspose2d(in_channels=self.in_channels,\n",
    "                                            out_channels=self.out_channels,\n",
    "                                            kernel_size=self.kernel_size,\n",
    "                                            output_padding=self.output_padding,\n",
    "                                            padding=self.padding,\n",
    "                                            stride=self.stride)\n",
    "\n",
    "\n",
    "        # Glorot initialization.\n",
    "        nn.init.xavier_normal_(self.real_convt.weight)\n",
    "        nn.init.xavier_normal_(self.im_convt.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_real = x[..., 0]\n",
    "        x_im = x[..., 1]\n",
    "\n",
    "        ct_real = self.real_convt(x_real) - self.im_convt(x_im)\n",
    "        ct_im = self.im_convt(x_real) + self.real_convt(x_im)\n",
    "\n",
    "        output = torch.stack([ct_real, ct_im], dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-UT9p42B8DV",
    "papermill": {
     "duration": 0.007415,
     "end_time": "2025-08-11T17:51:52.568047",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.560632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Layer per la batch normalization di segnali complessi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.584289Z",
     "iopub.status.busy": "2025-08-11T17:51:52.583779Z",
     "iopub.status.idle": "2025-08-11T17:51:52.589686Z",
     "shell.execute_reply": "2025-08-11T17:51:52.588859Z"
    },
    "id": "I3yANC1OCCIa",
    "papermill": {
     "duration": 0.015609,
     "end_time": "2025-08-11T17:51:52.591015",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.575406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ComplexBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.affine = affine\n",
    "        self.track_running_stats = track_running_stats\n",
    "\n",
    "        self.real_b = nn.BatchNorm2d(num_features=self.num_features, eps=self.eps, momentum=self.momentum,\n",
    "                                      affine=self.affine, track_running_stats=self.track_running_stats)\n",
    "        self.im_b = nn.BatchNorm2d(num_features=self.num_features, eps=self.eps, momentum=self.momentum,\n",
    "                                    affine=self.affine, track_running_stats=self.track_running_stats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_real = x[..., 0]\n",
    "        x_im = x[..., 1]\n",
    "\n",
    "        n_real = self.real_b(x_real)\n",
    "        n_im = self.im_b(x_im)\n",
    "\n",
    "        output = torch.stack([n_real, n_im], dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2odkCO2UCoDo",
    "papermill": {
     "duration": 0.007692,
     "end_time": "2025-08-11T17:51:52.606694",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.599002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Layer Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.623367Z",
     "iopub.status.busy": "2025-08-11T17:51:52.622668Z",
     "iopub.status.idle": "2025-08-11T17:51:52.628176Z",
     "shell.execute_reply": "2025-08-11T17:51:52.627567Z"
    },
    "id": "XgUrwf8cCr45",
    "papermill": {
     "duration": 0.01507,
     "end_time": "2025-08-11T17:51:52.629326",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.614256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, filter_size=(7,5), stride_size=(2,2), in_channels=1, out_channels=45, padding=(0,0)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.filter_size = filter_size\n",
    "        self.stride_size = stride_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.padding = padding\n",
    "\n",
    "        self.cconv = ComplexConv2d(in_channels=self.in_channels, out_channels=self.out_channels,\n",
    "                             kernel_size=self.filter_size, stride=self.stride_size, padding=self.padding)\n",
    "\n",
    "        self.cbn = ComplexBatchNorm2d(num_features=self.out_channels)\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        conved = self.cconv(x)\n",
    "        normed = self.cbn(conved)\n",
    "        acted = self.leaky_relu(normed)\n",
    "\n",
    "        return acted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_mwsQ_bDJsD",
    "papermill": {
     "duration": 0.00745,
     "end_time": "2025-08-11T17:51:52.644814",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.637364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Layer Decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.661390Z",
     "iopub.status.busy": "2025-08-11T17:51:52.660855Z",
     "iopub.status.idle": "2025-08-11T17:51:52.667317Z",
     "shell.execute_reply": "2025-08-11T17:51:52.666562Z"
    },
    "id": "4OMBVSdbDMBV",
    "papermill": {
     "duration": 0.015925,
     "end_time": "2025-08-11T17:51:52.668394",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.652469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, filter_size=(7,5), stride_size=(2,2), in_channels=1, out_channels=45,\n",
    "                 output_padding=(0,0), padding=(0,0), last_layer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.filter_size = filter_size\n",
    "        self.stride_size = stride_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.output_padding = output_padding\n",
    "        self.padding = padding\n",
    "\n",
    "        self.last_layer = last_layer\n",
    "\n",
    "        self.cconvt = ComplexConvTranspose2d(in_channels=self.in_channels, out_channels=self.out_channels,\n",
    "                             kernel_size=self.filter_size, stride=self.stride_size, output_padding=self.output_padding, padding=self.padding)\n",
    "\n",
    "        self.cbn = ComplexBatchNorm2d(num_features=self.out_channels)\n",
    "\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        conved = self.cconvt(x)\n",
    "\n",
    "        if not self.last_layer:\n",
    "            normed = self.cbn(conved)\n",
    "            output = self.leaky_relu(normed)\n",
    "        else:\n",
    "            m_phase = conved / (torch.abs(conved) + 1e-8)\n",
    "            m_mag = torch.tanh(torch.abs(conved))\n",
    "            output = m_phase * m_mag\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0E8Uf8UDiP5",
    "papermill": {
     "duration": 0.007402,
     "end_time": "2025-08-11T17:51:52.683744",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.676342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Funzione di Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.700665Z",
     "iopub.status.busy": "2025-08-11T17:51:52.700313Z",
     "iopub.status.idle": "2025-08-11T17:51:52.714826Z",
     "shell.execute_reply": "2025-08-11T17:51:52.714144Z"
    },
    "id": "XLFll7XfDlR1",
    "papermill": {
     "duration": 0.024596,
     "end_time": "2025-08-11T17:51:52.716018",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.691422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wsdr_fn(x_input, y_pred, y_target, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Loss function \n",
    "    \"\"\"    \n",
    "    # Verifica che y_pred abbia le dimensioni corrette\n",
    "    if y_pred.dim() < 3:\n",
    "        print(f\"ERRORE: y_pred ha dimensioni insufficienti: {y_pred.shape}\")\n",
    "        print(\"Probabilmente il modello ha fallito durante l'inference\")\n",
    "        # Restituisce una loss alta per segnalare il problema\n",
    "        return torch.tensor(1000.0, requires_grad=True, device=y_pred.device)\n",
    "    \n",
    "    # Controllo che tutti i tensori abbiano la stessa struttura\n",
    "    if y_target.dim() == 5:  # [batch, channel, freq, time, 2]\n",
    "        y_target = torch.squeeze(y_target, 1)  # [batch, freq, time, 2]\n",
    "    \n",
    "    if y_pred.dim() == 5:  # [batch, channel, freq, time, 2]\n",
    "        y_pred = torch.squeeze(y_pred, 1)  # [batch, freq, time, 2]\n",
    "    elif y_pred.dim() == 4:  # Già nel formato corretto\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"ERRORE: Dimensioni y_pred non supportate: {y_pred.shape}\")\n",
    "        return torch.tensor(1000.0, requires_grad=True, device=y_pred.device)\n",
    "    \n",
    "    # Verifica compatibilità dimensioni\n",
    "    if y_pred.shape != y_target.shape:\n",
    "        print(f\"ERRORE: Shape mismatch - pred: {y_pred.shape}, target: {y_target.shape}\")\n",
    "        return torch.tensor(1000.0, requires_grad=True, device=y_pred.device)\n",
    "    \n",
    "    try:\n",
    "        # Converto in formato complesso\n",
    "        y_true_complex = torch.complex(y_target[..., 0], y_target[..., 1])\n",
    "        y_pred_complex = torch.complex(y_pred[..., 0], y_pred[..., 1])\n",
    "        \n",
    "        \n",
    "        # Converto in dominio temporale\n",
    "        y_target_time = torch.istft(y_true_complex, n_fft=n_fft, hop_length=hop_length, \n",
    "                                   window=window, normalized=True)\n",
    "        y_pred_time = torch.istft(y_pred_complex, n_fft=n_fft, hop_length=hop_length,\n",
    "                                 window=window, normalized=True)\n",
    "        \n",
    "        # Controllo che abbiano la stessa lunghezza\n",
    "        min_len = min(y_target_time.shape[-1], y_pred_time.shape[-1])\n",
    "        y_target_time = y_target_time[..., :min_len]\n",
    "        y_pred_time = y_pred_time[..., :min_len]\n",
    "        \n",
    "        # Calcolo SDR loss\n",
    "        def sdr_fn(true, pred, eps=1e-8):\n",
    "            # Flatten per il calcolo\n",
    "            true_flat = true.flatten(1)  # [batch, samples]\n",
    "            pred_flat = pred.flatten(1)  # [batch, samples]\n",
    "            \n",
    "            # Normalizzo per evitare overflow\n",
    "            true_norm = true_flat / (torch.norm(true_flat, dim=-1, keepdim=True) + eps)\n",
    "            pred_norm = pred_flat / (torch.norm(pred_flat, dim=-1, keepdim=True) + eps)\n",
    "            \n",
    "            # Calcolo correlazione\n",
    "            correlation = torch.sum(true_norm * pred_norm, dim=-1)\n",
    "            return -correlation  # Massimizza correlazione\n",
    "        \n",
    "        sdr_loss = sdr_fn(y_target_time, y_pred_time)\n",
    "        return torch.mean(sdr_loss)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERRORE nella loss function: {e}\")\n",
    "        print(f\"y_pred shape: {y_pred.shape}\")\n",
    "        print(f\"y_target shape: {y_target.shape}\")\n",
    "        return torch.tensor(1000.0, requires_grad=True, device=y_pred.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007381,
     "end_time": "2025-08-11T17:51:52.778469",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.771088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.817633Z",
     "iopub.status.busy": "2025-08-11T17:51:52.817380Z",
     "iopub.status.idle": "2025-08-11T17:51:52.828510Z",
     "shell.execute_reply": "2025-08-11T17:51:52.827689Z"
    },
    "papermill": {
     "duration": 0.020881,
     "end_time": "2025-08-11T17:51:52.829797",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.808916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gather_all_snr_improvements(loader, model, stft_to_waveform, device):\n",
    "    snr_improvements = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (noisy, clean) in enumerate(loader):\n",
    "            #print(f\"\\nSample {i+1}\")\n",
    "            #print(\" - noisy shape:\", noisy.shape, \"clean shape:\", clean.shape)\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "            pred = model(noisy, is_istft=False)\n",
    "            #print(\" - pred shape:\", pred.shape)\n",
    "\n",
    "            clean_wave = stft_to_waveform(clean)\n",
    "            noisy_wave = stft_to_waveform(noisy)\n",
    "            pred_wave = stft_to_waveform(pred)\n",
    "            #print(\" - clean_wave shape:\", clean_wave.shape,\n",
    "                  #\"noisy_wave shape:\", noisy_wave.shape,\n",
    "                  #\"pred_wave shape:\", pred_wave.shape)\n",
    "\n",
    "            min_len = min(clean_wave.shape[-1], noisy_wave.shape[-1], pred_wave.shape[-1])\n",
    "            #print(\" - min_len:\", min_len)\n",
    "            clean_wave = clean_wave[..., :min_len]\n",
    "            noisy_wave = noisy_wave[..., :min_len]\n",
    "            pred_wave = pred_wave[..., :min_len]\n",
    "\n",
    "            clean_np = clean_wave.squeeze().cpu().numpy()\n",
    "            noisy_np = noisy_wave.squeeze().cpu().numpy()\n",
    "            pred_np = pred_wave.squeeze().cpu().numpy()\n",
    "\n",
    "            numerator = np.sum(clean_np**2)\n",
    "            denominator_noisy = np.sum((clean_np - noisy_np)**2)\n",
    "            denominator_pred = np.sum((clean_np - pred_np)**2)\n",
    "            snr_before = 10 * np.log10(numerator / (denominator_noisy + 1e-8))\n",
    "            snr_after = 10 * np.log10(numerator / (denominator_pred + 1e-8))\n",
    "            improvement = snr_after - snr_before\n",
    "            #print(f\" - SNR before: {snr_before:.2f} dB, SNR after: {snr_after:.2f} dB, improvement: {improvement:.2f} dB\")\n",
    "            snr_improvements.append(improvement)\n",
    "\n",
    "    # DEBUG FINALE\n",
    "    #print(f\"Lista finale: {len(snr_improvements)} valori\")\n",
    "    print(f\"Range: {min(snr_improvements):.2f} - {max(snr_improvements):.2f} dB\")\n",
    "\n",
    "    return snr_improvements\n",
    "\n",
    "_histogram_counter = 0\n",
    "def plot_snr_histograms(full_snr_list):\n",
    "\n",
    "    global _histogram_counter\n",
    "    _histogram_counter += 1\n",
    "    \n",
    "    if len(full_snr_list) == 0:\n",
    "        print(\"Lista SNR vuota!\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(full_snr_list, bins=50, alpha=0.8, label='Test Set', color='blue')\n",
    "    plt.axvline(np.mean(full_snr_list), color='red', linestyle='dashed', linewidth=2, \n",
    "                label=f'Media: {np.mean(full_snr_list):.2f} dB')\n",
    "    plt.title('Distribuzione SNR Improvement - Test Set')\n",
    "    plt.xlabel('SNR Improvement (dB)')\n",
    "    plt.ylabel('Frequenza')\n",
    "    plt.legend()\n",
    "\n",
    "    filename = f'/kaggle/working/snr_histogram_epoch_{_histogram_counter:02d}.png'\n",
    "    \n",
    "    # SALVATAGGIO E VISUALIZZAZIONE\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Grafico plot_snr_histograms salvato!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.795454Z",
     "iopub.status.busy": "2025-08-11T17:51:52.795166Z",
     "iopub.status.idle": "2025-08-11T17:51:52.799896Z",
     "shell.execute_reply": "2025-08-11T17:51:52.799301Z"
    },
    "papermill": {
     "duration": 0.014729,
     "end_time": "2025-08-11T17:51:52.800998",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.786269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stft_to_waveform(stft_tensor, n_fft=n_fft, hop_length=hop_length):\n",
    "    \"\"\"Converte STFT in waveform\"\"\"\n",
    "    if stft_tensor.dim() == 5:  # [batch, channel, freq, time, 2]\n",
    "        stft_tensor = torch.squeeze(stft_tensor, 1)\n",
    "    elif stft_tensor.dim() == 4:  # [batch, freq, time, 2]\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Unexpected tensor dimensions: {stft_tensor.shape}\")\n",
    "        return None\n",
    "    \n",
    "    # Converto in complesso\n",
    "    complex_tensor = torch.complex(stft_tensor[..., 0], stft_tensor[..., 1])\n",
    "    \n",
    "    # Applico ISTFT\n",
    "    waveform = torch.istft(complex_tensor, n_fft=n_fft, hop_length=hop_length, \n",
    "                          window=window, normalized=True)\n",
    "    return waveform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WRdpPg7L60k",
    "papermill": {
     "duration": 0.007416,
     "end_time": "2025-08-11T17:51:52.845246",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.837830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Allenamento epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.861887Z",
     "iopub.status.busy": "2025-08-11T17:51:52.861165Z",
     "iopub.status.idle": "2025-08-11T17:51:52.867310Z",
     "shell.execute_reply": "2025-08-11T17:51:52.866537Z"
    },
    "id": "Cq1pXZKwMKkR",
    "papermill": {
     "duration": 0.015624,
     "end_time": "2025-08-11T17:51:52.868469",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.852845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(net, train_loader, loss_fn, optimizer):\n",
    "    net.train()\n",
    "    train_ep_loss = 0.\n",
    "    counter = 0\n",
    "    lr_per_batch = []\n",
    "    \n",
    "    for noisy_input, noisy_target in train_loader:\n",
    "        noisy_input, noisy_target = noisy_input.to(device), noisy_target.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            pred_x = net(noisy_input, is_istft=False)  # Mantengo in dominio STFT\n",
    "            \n",
    "            loss = loss_fn(noisy_input, pred_x, noisy_target)\n",
    "            \n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(\"NaN/Inf loss detected, skipping batch\")\n",
    "                continue\n",
    "                \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            lr_per_batch.append(current_lr)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            train_ep_loss += loss.item()\n",
    "            counter += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in training: {e}\")\n",
    "            print(f\"Input shape: {noisy_input.shape}\")\n",
    "            print(f\"Target shape: {noisy_target.shape}\")\n",
    "            continue\n",
    "    \n",
    "    avg_loss = train_ep_loss / max(counter, 1)\n",
    "    \n",
    "    if len(lr_per_batch) > 0:\n",
    "        lr_first = lr_per_batch[0]\n",
    "        lr_last = lr_per_batch[-1]\n",
    "        lr_min = min(lr_per_batch)\n",
    "        lr_max = max(lr_per_batch)\n",
    "    else:\n",
    "        lr_first = lr_last = lr_min = lr_max = float('nan')\n",
    "    \n",
    "    return avg_loss, {\n",
    "        \"lr_first_batch\": lr_first,\n",
    "        \"lr_last_batch\": lr_last,\n",
    "        \"lr_min\": lr_min,\n",
    "        \"lr_max\": lr_max,\n",
    "        \"lr_steps\": len(lr_per_batch)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTvg0ce0PUtx",
    "papermill": {
     "duration": 0.007794,
     "end_time": "2025-08-11T17:51:52.884354",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.876560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validazione del modello durante il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.901222Z",
     "iopub.status.busy": "2025-08-11T17:51:52.900587Z",
     "iopub.status.idle": "2025-08-11T17:51:52.908031Z",
     "shell.execute_reply": "2025-08-11T17:51:52.907463Z"
    },
    "id": "yRXqzT3GPYil",
    "papermill": {
     "duration": 0.016969,
     "end_time": "2025-08-11T17:51:52.909104",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.892135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_epoch(net, test_loader, loss_fn, use_net=True):\n",
    "    net.eval()\n",
    "    test_ep_loss = 0.\n",
    "    counter = 0\n",
    "    \n",
    "    for noisy_x, clean_x in test_loader:\n",
    "        noisy_x, clean_x = noisy_x.to(device), clean_x.to(device)\n",
    "        \n",
    "        try:\n",
    "            pred_x = net(noisy_x, is_istft=False)  # Mantiene in dominio STFT\n",
    "            \n",
    "            # Verifica che la predizione abbia senso\n",
    "            if pred_x.dim() < 3:\n",
    "                print(f\"ERRORE: Predizione con dimensioni sbagliate: {pred_x.shape}\")\n",
    "                continue\n",
    "                \n",
    "            loss = loss_fn(noisy_x, pred_x, clean_x)\n",
    "            \n",
    "            if torch.isnan(loss) or torch.isinf(loss) or loss.item() > 100:\n",
    "                print(f\"Loss anomala: {loss.item()}, saltando batch\")\n",
    "                continue\n",
    "                \n",
    "            test_ep_loss += loss.item()\n",
    "            counter += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel test batch: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if counter == 0:\n",
    "        print(\"ATTENZIONE: Nessun batch valido nel test!\")\n",
    "        return float('inf'), {}\n",
    "    \n",
    "    test_ep_loss /= counter\n",
    "    \n",
    "    # Calcolo metriche sui dati di test (solo se ci sono batch validi)\n",
    "    try:\n",
    "        # Esegui tutto il test set e raccogli tutti gli SNR improvement\n",
    "        snr_full = gather_all_snr_improvements(test_loader, net, stft_to_waveform, device)\n",
    "        mean_snr = np.mean(snr_full)\n",
    "        negativi = np.sum(np.array(snr_full) < 0)\n",
    "        print(f\"Media SNR improvement test set: {mean_snr:.2f} dB — peggiorati: {negativi}/{len(snr_full)}\")\n",
    "        plot_snr_histograms(snr_full)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel calcolo metriche: {e}\")\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return test_ep_loss, mean_snr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vp2FFhaW-3Y",
    "papermill": {
     "duration": 0.008008,
     "end_time": "2025-08-11T17:51:52.949348",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.941340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stampa della Loss del train e del test durante l'allenamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:52.983812Z",
     "iopub.status.busy": "2025-08-11T17:51:52.983206Z",
     "iopub.status.idle": "2025-08-11T17:51:52.991848Z",
     "shell.execute_reply": "2025-08-11T17:51:52.991019Z"
    },
    "id": "RraLNmxHXS4B",
    "papermill": {
     "duration": 0.019006,
     "end_time": "2025-08-11T17:51:52.993075",
     "exception": false,
     "start_time": "2025-08-11T17:51:52.974069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(net, train_loader, test_loader, loss_fn, optimizer, scheduler, epochs):\n",
    "\n",
    "    # Debug iniziale delle dimensioni\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    sample_input = sample_batch[0].to(device)\n",
    "    \n",
    "    if not debug_shapes(net, sample_input):\n",
    "        print(\"Training interrotto - Problemi dimensionali!\")\n",
    "        return [], []\n",
    "        \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    best_metric = float('-inf') \n",
    "    best_path = base_dir / \"Weights\" / \"dc20_best.pth\"\n",
    "\n",
    "    for e in tqdm(range(epochs)):\n",
    "        # STAMPA LEARNING RATE ALL'INIZIO DELL'EPOCA\n",
    "        train_loss, lr_stats = train_epoch(net, train_loader, loss_fn, optimizer)\n",
    "    \n",
    "        # Stampa riassunto LR dell’epoca\n",
    "        print(\n",
    "            f\"[LR] Epoch {e+1}: \"\n",
    "            f\"first={lr_stats['lr_first_batch']:.3e}, \"\n",
    "            f\"last={lr_stats['lr_last_batch']:.3e}, \"\n",
    "            f\"min={lr_stats['lr_min']:.3e}, \"\n",
    "            f\"max={lr_stats['lr_max']:.3e}, \"\n",
    "            f\"steps={lr_stats['lr_steps']}\"\n",
    "        )\n",
    "        \n",
    "        # Esegui un'epoca di test (validazione)\n",
    "        with torch.no_grad():\n",
    "            test_loss, mean_snr = test_epoch(net, test_loader, loss_fn, use_net=True)\n",
    "            if mean_snr is not None and mean_snr > best_metric:\n",
    "                best_metric = mean_snr\n",
    "                torch.save(net.state_dict(), best_path)\n",
    "                print(f\"Nuovo best: SNR_metric {best_metric:.6f}. Salvato dc20_best.pth\")\n",
    "        \n",
    "        #scheduler.step(test_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        print(\"Loss: {:.6f}...\".format(train_loss),\n",
    "              \"Test Loss: {:.6f}\".format(test_loss))\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5FhkO2JZ60q",
    "papermill": {
     "duration": 0.007899,
     "end_time": "2025-08-11T17:51:53.009505",
     "exception": false,
     "start_time": "2025-08-11T17:51:53.001606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modello a 20 layer della DCUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:53.027941Z",
     "iopub.status.busy": "2025-08-11T17:51:53.027578Z",
     "iopub.status.idle": "2025-08-11T17:51:53.196916Z",
     "shell.execute_reply": "2025-08-11T17:51:53.196292Z"
    },
    "id": "NWQZYjNTaFWn",
    "papermill": {
     "duration": 0.180467,
     "end_time": "2025-08-11T17:51:53.198197",
     "exception": false,
     "start_time": "2025-08-11T17:51:53.017730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DCUnet20(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net complessa che predice maschera in STFT (real/imag). Output same-shape dello STFT input.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_fft=2048, hop_length=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "        self.set_size(model_complexity=32, input_channels=1, model_depth=20)\n",
    "\n",
    "        # costruzione degli encoder\n",
    "        self.encoders = []\n",
    "        self.model_length = 20 // 2  # → 10 encoder e 10 decoder\n",
    "\n",
    "        for i in range(self.model_length):\n",
    "            module = Encoder(in_channels=self.enc_channels[i], out_channels=self.enc_channels[i + 1],\n",
    "                             filter_size=self.enc_kernel_sizes[i], stride_size=self.enc_strides[i], padding=self.enc_paddings[i])\n",
    "            self.add_module(\"encoder{}\".format(i), module)\n",
    "            self.encoders.append(module)\n",
    "\n",
    "        # costruzione dei decoder\n",
    "        self.decoders = []\n",
    "        \n",
    "        for i in range(self.model_length):\n",
    "            if i != self.model_length - 1:\n",
    "                # Il primo decoder non deve sommare le skip connections nell'input\n",
    "                if i == 0:\n",
    "                    # Primo decoder: solo i canali dall'encoder finale\n",
    "                    in_channels = self.dec_channels[i]\n",
    "                else:\n",
    "                    # Altri decoder: canali decoder + skip connection\n",
    "                    in_channels = self.dec_channels[i] + self.enc_channels[self.model_length - i]\n",
    "                    \n",
    "                module = Decoder(in_channels=in_channels, \n",
    "                                out_channels=self.dec_channels[i + 1],\n",
    "                                filter_size=self.dec_kernel_sizes[i], \n",
    "                                stride_size=self.dec_strides[i], \n",
    "                                padding=self.dec_paddings[i],\n",
    "                                output_padding=self.dec_output_padding[i])\n",
    "            else:\n",
    "                # Ultimo decoder\n",
    "                in_channels = self.dec_channels[i] + self.enc_channels[self.model_length - i]\n",
    "                module = Decoder(in_channels=in_channels, \n",
    "                                out_channels=self.dec_channels[i + 1],\n",
    "                                filter_size=self.dec_kernel_sizes[i], \n",
    "                                stride_size=self.dec_strides[i], \n",
    "                                padding=self.dec_paddings[i],\n",
    "                                output_padding=self.dec_output_padding[i], \n",
    "                                last_layer=True)\n",
    "            \n",
    "            self.add_module(\"decoder{}\".format(i), module)\n",
    "            self.decoders.append(module)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, is_istft=True):\n",
    "        orig_x = x\n",
    "        xs = []\n",
    "        \n",
    "        # Controllo che l'input abbia dimensioni corrette\n",
    "        if x.dim() == 4:  # [batch, freq, time, 2]\n",
    "            x = x.unsqueeze(1)  # [batch, 1, freq, time, 2]\n",
    "        \n",
    "        # Encoder (mantieni dimensioni consistenti)\n",
    "        for i, encoder in enumerate(self.encoders):\n",
    "            xs.append(x)\n",
    "            x = encoder(x)\n",
    "            #print(f\"Encoder {i}: {x.shape}\")\n",
    "        \n",
    "        # Decoder con controlli\n",
    "        p = x\n",
    "        for i, decoder in enumerate(self.decoders):\n",
    "            p = decoder(p)\n",
    "            #print(f\"Decoder {i} output: {p.shape}\")\n",
    "            \n",
    "            if i < self.model_length - 1:\n",
    "                skip_connection = xs[self.model_length - 1 - i]\n",
    "                #print(f\"Skip connection {i}: {skip_connection.shape}\")\n",
    "                \n",
    "                # CONTROLLO delle dimensioni\n",
    "                if p.shape[2:4] != skip_connection.shape[2:4]:\n",
    "                    print(f\"ERRORE: Dimensioni incompatibili!\")\n",
    "                    print(f\"Decoder: {p.shape}, Skip: {skip_connection.shape}\")\n",
    "                    return torch.zeros_like(orig_x)\n",
    "                \n",
    "                p = torch.cat([p, skip_connection], dim=1)\n",
    "        \n",
    "        # Output finale\n",
    "        mask = p\n",
    "        output = mask * orig_x.unsqueeze(1) if orig_x.dim() == 4 else mask * orig_x\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def set_size(self, model_complexity, model_depth=20, input_channels=1):\n",
    "      # definisce tutte le dimensioni e i parametri per encoder e decoder, specifici per la versione a 20 layer\n",
    "\n",
    "        if model_depth == 20:\n",
    "            self.enc_channels = [input_channels,\n",
    "                                 model_complexity,\n",
    "                                 model_complexity,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 4]\n",
    "\n",
    "            self.enc_kernel_sizes = [(7, 1),\n",
    "                                     (1, 7),\n",
    "                                     (6, 4),\n",
    "                                     (7, 5),\n",
    "                                     (5, 3),\n",
    "                                     (5, 3),\n",
    "                                     (5, 3),\n",
    "                                     (5, 3),\n",
    "                                     (5, 3),\n",
    "                                     (5, 3)]\n",
    "\n",
    "            self.enc_strides = [(1, 1),\n",
    "                                (1, 1),\n",
    "                                (2, 2),\n",
    "                                (2, 1),\n",
    "                                (2, 2),\n",
    "                                (2, 1),\n",
    "                                (2, 2),\n",
    "                                (2, 1),\n",
    "                                (2, 2),\n",
    "                                (2, 1)]\n",
    "\n",
    "            self.enc_paddings = [(3, 0),\n",
    "                                 (0, 3),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (2, 0),\n",
    "                                 (0, 0)]\n",
    "\n",
    "            self.dec_channels = [model_complexity * 4,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity * 2,\n",
    "                                 model_complexity,\n",
    "                                 model_complexity,\n",
    "                                 input_channels]\n",
    "\n",
    "            self.dec_kernel_sizes = [(6, 3),\n",
    "                                     (3, 3),\n",
    "                                     (6, 3),\n",
    "                                     (6, 3),\n",
    "                                     (6, 3),\n",
    "                                     (6, 4),\n",
    "                                     (8, 5),\n",
    "                                     (7, 5),\n",
    "                                     (1, 7),\n",
    "                                     (7, 1)]\n",
    "\n",
    "            self.dec_strides = [(2, 1), #\n",
    "                                (2, 2), #\n",
    "                                (2, 1), #\n",
    "                                (2, 2), #\n",
    "                                (2, 1), #\n",
    "                                (2, 2), #\n",
    "                                (2, 1), #\n",
    "                                (2, 2), #\n",
    "                                (1, 1),\n",
    "                                (1, 1)]\n",
    "\n",
    "            self.dec_paddings = [(0, 0),\n",
    "                                 (1, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 0),\n",
    "                                 (0, 3),\n",
    "                                 (3, 0)]\n",
    "\n",
    "            self.dec_output_padding = [(0,0),\n",
    "                                       (1,0),\n",
    "                                       (0,0),\n",
    "                                       (0,0),\n",
    "                                       (0,0),\n",
    "                                       (0,0),\n",
    "                                       (0,0),\n",
    "                                       (0,0),\n",
    "                                       (0,0),\n",
    "                                       (0,0)]\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model depth : {}\".format(model_depth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:53.216059Z",
     "iopub.status.busy": "2025-08-11T17:51:53.215792Z",
     "iopub.status.idle": "2025-08-11T17:51:53.220112Z",
     "shell.execute_reply": "2025-08-11T17:51:53.219515Z"
    },
    "papermill": {
     "duration": 0.014104,
     "end_time": "2025-08-11T17:51:53.221226",
     "exception": false,
     "start_time": "2025-08-11T17:51:53.207122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def debug_shapes(model, sample_input):\n",
    "    \"\"\"Debug delle dimensioni attraverso il modello\"\"\"\n",
    "    #print(f\"Input shape: {sample_input.shape}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(sample_input, is_istft=False)\n",
    "        #print(f\"Output shape: {output.shape}\")\n",
    "        \n",
    "        if output.shape != sample_input.shape:\n",
    "            print(\"ERRORE: Output != Input shape!\")\n",
    "            return False\n",
    "        else:\n",
    "            #print(\"Dimensioni corrette\")\n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUz-5hUCFaX0",
    "papermill": {
     "duration": 0.007658,
     "end_time": "2025-08-11T17:51:53.236903",
     "exception": false,
     "start_time": "2025-08-11T17:51:53.229245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Allenamento della rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T17:51:53.253343Z",
     "iopub.status.busy": "2025-08-11T17:51:53.253069Z",
     "iopub.status.idle": "2025-08-12T05:49:44.625741Z",
     "shell.execute_reply": "2025-08-12T05:49:44.624944Z"
    },
    "id": "q7sBQ4qyFfFq",
    "outputId": "599fc063-9429-4080-d886-83f89483abb7",
    "papermill": {
     "duration": 43071.382596,
     "end_time": "2025-08-12T05:49:44.627096",
     "exception": false,
     "start_time": "2025-08-11T17:51:53.244500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "dcunet20 = DCUnet20(n_fft, hop_length).to(device)\n",
    "\n",
    "# DEBUG DELLE DIMENSIONI\n",
    "#print(\"Verificando dimensioni del modello...\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_input = sample_batch[0].to(device)\n",
    "\n",
    "if not debug_shapes(dcunet20, sample_input):\n",
    "    print(\"FERMA IL TRAINING - Problemi dimensionali!\")\n",
    "    exit()\n",
    "    \n",
    "loss_fn = wsdr_fn\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "        dcunet20.parameters(),\n",
    "        lr=5e-5,  # Learning rate iniziale\n",
    "        weight_decay=1e-4,\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1.5e-4,\n",
    "        epochs=10,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.15,  # Warm-up al 15%\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=4.0,   # max_lr/div_factor = lr iniziale\n",
    "        final_div_factor=20.0  # lr finale = max_lr/final_div_factor\n",
    "    )\n",
    "\n",
    "# per riprendere l’allenamento da un checkpoint salvato in precedenza\n",
    "#model_checkpoint = torch.load(\"/kaggle/input/segments4/pytorch/default/1/dc20_model_4.pth\")\n",
    "#dcunet20.load_state_dict(model_checkpoint)\n",
    "\n",
    "# lancia l’allenamento del modello per 10 epoche, salvando le perdite di training e validation.\n",
    "train_losses, validation_losses = train(dcunet20, train_loader, test_loader, loss_fn, optimizer, scheduler, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ay63BHhPQhd",
    "papermill": {
     "duration": 0.010433,
     "end_time": "2025-08-12T05:49:44.648485",
     "exception": false,
     "start_time": "2025-08-12T05:49:44.638052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prova dei modelli allenati con valutazioni e grafici di confronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Device e parametri globali\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class AudioProcessor:\n",
    "    \"\"\"Classe per gestire elaborazione audio\"\"\"\n",
    "    \n",
    "    def __init__(self, n_fft, hop_length, sample_rate):\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window = torch.hann_window(n_fft).to(device)\n",
    "\n",
    "    def stft_to_waveform(self, stft_tensor):\n",
    "        \"\"\"Conversione STFT->waveform\"\"\"\n",
    "        if stft_tensor.dim() == 5:\n",
    "            stft_tensor = stft_tensor[0, 0]\n",
    "        elif stft_tensor.dim() == 4:\n",
    "            stft_tensor = stft_tensor[0]\n",
    "        \n",
    "        complex_tensor = torch.view_as_complex(stft_tensor)\n",
    "        waveform = torch.istft(\n",
    "            complex_tensor,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            window=self.window,\n",
    "            normalized=True,\n",
    "            return_complex=False\n",
    "        )\n",
    "        return waveform\n",
    "\n",
    "    def ensure_waveform(self, tensor):\n",
    "        \"\"\"Converte tensor a waveform\"\"\"\n",
    "        if tensor.dim() >= 3 and tensor.size(-1) == 2:\n",
    "            return self.stft_to_waveform(tensor)\n",
    "        else:\n",
    "            while tensor.dim() > 1 and tensor.size(0) == 1:\n",
    "                tensor = tensor.squeeze(0)\n",
    "            return tensor\n",
    "\n",
    "class SingleSamplePlotter:\n",
    "    def __init__(self, sample_rate, save_dir='/kaggle/working'):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(exist_ok=True)\n",
    "    def plot(self, clean_wave, noisy_wave, predicted_wave, sample_idx, snr_value, snr_improvement):\n",
    "        def to_numpy(tensor):\n",
    "            if torch.is_tensor(tensor):\n",
    "                return tensor.detach().cpu().numpy().squeeze()\n",
    "            return np.asarray(tensor).squeeze()\n",
    "        try:\n",
    "            clean_np, noisy_np, pred_np = map(to_numpy, [clean_wave, noisy_wave, predicted_wave])\n",
    "            min_len = min(len(clean_np), len(noisy_np), len(pred_np))\n",
    "            clean_np = clean_np[:min_len]\n",
    "            noisy_np = noisy_np[:min_len]\n",
    "            pred_np = pred_np[:min_len]\n",
    "            time_axis = np.arange(min_len) / self.sample_rate\n",
    "            fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "            colors = ['#2E8B57', '#DC143C', '#1E90FF']\n",
    "            signals = [('Clean (Ref)', clean_np), ('Noisy (Input)', noisy_np), ('Denoised (Output)', pred_np)]\n",
    "            for i, (label, signal) in enumerate(signals):\n",
    "                axes[i].plot(time_axis, signal, color=colors[i], linewidth=0.8, alpha=0.9)\n",
    "                if i == 2:\n",
    "                    title = f'{label} - SNR: {snr_value:.2f} dB | ΔSNR: {snr_improvement:+.2f} dB'\n",
    "                else:\n",
    "                    title = f'Sample {sample_idx} - {label}'\n",
    "                axes[i].set_title(title, fontsize=11)\n",
    "                axes[i].set_ylabel('Amplitude')\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "            axes[-1].set_xlabel('Time (seconds)')\n",
    "            plt.tight_layout()\n",
    "            filename = self.save_dir / f'sample_{sample_idx:03d}_plot.png'\n",
    "            plt.savefig(filename, dpi=120, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            return str(filename)\n",
    "        except Exception as e:\n",
    "            print(f\" Errore plot campione {sample_idx}: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "class SNRCalculator:\n",
    "    \"\"\"Classe per calcoli SNR\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_snr(clean, estimate, epsilon=1e-10):\n",
    "        signal_power = torch.sum(clean ** 2)\n",
    "        noise_power = torch.sum((clean - estimate) ** 2)\n",
    "        noise_power = torch.clamp(noise_power, min=epsilon)\n",
    "        snr = 10 * torch.log10(signal_power / noise_power)\n",
    "        return snr.item()\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_ssnr(clean, estimate, frame_length=1440, frame_shift=720, C_min=-10, C_max=35):\n",
    "        clean = clean.squeeze().cpu().numpy()\n",
    "        estimate = estimate.squeeze().cpu().numpy()\n",
    "        min_len = min(len(clean), len(estimate))\n",
    "        clean = clean[:min_len]\n",
    "        estimate = estimate[:min_len]\n",
    "        n_frames = (min_len - frame_length) // frame_shift + 1\n",
    "        if n_frames < 1:\n",
    "            return float('nan')\n",
    "        ssnr_list = []\n",
    "        for i in range(n_frames):\n",
    "            start = i * frame_shift\n",
    "            end = start + frame_length\n",
    "            c_seg = clean[start:end]\n",
    "            e_seg = estimate[start:end]\n",
    "            num = np.sum(c_seg ** 2)\n",
    "            den = np.sum((c_seg - e_seg) ** 2)\n",
    "            # Proteggi il rapporto\n",
    "            ratio = num / (den + 1e-8)\n",
    "            if ratio <= 0 or not np.isfinite(ratio):\n",
    "                snr = C_min\n",
    "            else:\n",
    "                snr = 10 * np.log10(ratio)\n",
    "            snr = np.clip(snr, C_min, C_max)\n",
    "            ssnr_list.append(snr)\n",
    "        return np.mean(ssnr_list)\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def align_tensors(*tensors):\n",
    "        min_len = min(t.shape[-1] for t in tensors)\n",
    "        return [t[..., :min_len] for t in tensors]\n",
    "\n",
    "def save_audio_sample(clean_wave, noisy_wave, predicted_wave, sample_idx, \n",
    "                     sample_rate, save_dir='/kaggle/working'):\n",
    "    \"\"\"Salva i tre audio (clean, noisy, denoised) per un campione specifico\"\"\"\n",
    "    \n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    def to_cpu_tensor(tensor):\n",
    "        if torch.is_tensor(tensor):\n",
    "            return tensor.detach().cpu().unsqueeze(0) if tensor.dim() == 1 else tensor.detach().cpu()\n",
    "        return torch.tensor(tensor).unsqueeze(0)\n",
    "    \n",
    "    # Converti a tensori CPU\n",
    "    clean_cpu = to_cpu_tensor(clean_wave)\n",
    "    noisy_cpu = to_cpu_tensor(noisy_wave)\n",
    "    predicted_cpu = to_cpu_tensor(predicted_wave)\n",
    "    \n",
    "    # Salva i file audio\n",
    "    files_saved = []\n",
    "    \n",
    "    try:\n",
    "        clean_file = save_path / f'sample_{sample_idx:03d}_clean.wav'\n",
    "        torchaudio.save(str(clean_file), clean_cpu, sample_rate)\n",
    "        files_saved.append(str(clean_file))\n",
    "        \n",
    "        noisy_file = save_path / f'sample_{sample_idx:03d}_noisy.wav'\n",
    "        torchaudio.save(str(noisy_file), noisy_cpu, sample_rate)\n",
    "        files_saved.append(str(noisy_file))\n",
    "        \n",
    "        denoised_file = save_path / f'sample_{sample_idx:03d}_denoised.wav'\n",
    "        torchaudio.save(str(denoised_file), predicted_cpu, sample_rate)\n",
    "        files_saved.append(str(denoised_file))\n",
    "        \n",
    "        print(f\" Audio salvati per campione {sample_idx}:\")\n",
    "        for file in files_saved:\n",
    "            print(f\"   • {Path(file).name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Errore salvataggio audio campione {sample_idx}: {e}\")\n",
    "    \n",
    "    return files_saved\n",
    "\n",
    "def evaluate_testset(model, test_loader, audio_processor, snr_calculator, \n",
    "                    sample_rate, save_audio_for=None, plot_samples=None, plotter=None):\n",
    "    \"\"\"Valutazione del test set con opzione salvataggio audio\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    snr_values = []\n",
    "    snr_improvements = []\n",
    "    ssnr_values = []\n",
    "    ssnr_improvements = []\n",
    "\n",
    "    \n",
    "    print(\" Avvio valutazione test set...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (noisy_input, clean_input) in enumerate(tqdm(test_loader, desc=\"Processing\")):\n",
    "            try:\n",
    "                noisy_input = noisy_input.to(device, non_blocking=True)\n",
    "                clean_input = clean_input.to(device, non_blocking=True)\n",
    "                \n",
    "                # Predizione\n",
    "                predicted_output = model(noisy_input, is_istft=True)\n",
    "                \n",
    "                # Conversione a waveform\n",
    "                predicted_wave = audio_processor.ensure_waveform(predicted_output)\n",
    "                clean_wave = audio_processor.ensure_waveform(clean_input)\n",
    "                noisy_wave = audio_processor.ensure_waveform(noisy_input)\n",
    "                \n",
    "                # Allineamento\n",
    "                clean_aligned, predicted_aligned, noisy_aligned = snr_calculator.align_tensors(\n",
    "                    clean_wave, predicted_wave, noisy_wave)\n",
    "                \n",
    "                # Calcolo SNR\n",
    "                snr_pred = snr_calculator.compute_snr(clean_aligned, predicted_aligned)\n",
    "                snr_noisy = snr_calculator.compute_snr(clean_aligned, noisy_aligned)\n",
    "                snr_improvement = snr_pred - snr_noisy\n",
    "\n",
    "                # SSNR e miglioramento\n",
    "                ssnr_pred = snr_calculator.compute_ssnr(clean_aligned, predicted_aligned)\n",
    "                ssnr_noisy = snr_calculator.compute_ssnr(clean_aligned, noisy_aligned)\n",
    "                ssnr_improvement = ssnr_pred - ssnr_noisy\n",
    "                \n",
    "                snr_values.append(snr_pred)\n",
    "                snr_improvements.append(snr_improvement)\n",
    "                ssnr_values.append(ssnr_pred)\n",
    "                ssnr_improvements.append(ssnr_improvement)\n",
    "                \n",
    "                # Salva audio se richiesto per questo campione\n",
    "                if save_audio_for and (i + 1) in save_audio_for:\n",
    "                    save_audio_sample(clean_aligned, noisy_aligned, predicted_aligned, \n",
    "                                    i + 1, sample_rate)\n",
    "                # Salva plot se richiesto\n",
    "                if plotter and plot_samples and (i + 1) in plot_samples:\n",
    "                    plot_path = plotter.plot(clean_aligned, noisy_aligned, predicted_aligned, i + 1, snr_pred, snr_improvement)\n",
    "                    print(f\" Plot salvato per sample {i+1}: {plot_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\" Errore campione {i+1}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return snr_values, snr_improvements, ssnr_values, ssnr_improvements\n",
    "\n",
    "def plot_results(snr_values, snr_improvements, save_dir='/kaggle/working'):\n",
    "    \"\"\"Crea i due istogrammi delle distribuzioni\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Distribuzione SNR\n",
    "    ax1.hist(snr_values, bins=40, alpha=0.7, color='blue', edgecolor='navy')\n",
    "    mean_snr = np.mean(snr_values)\n",
    "    # ax1.set_xlim(0, 30) PER SETTARE DIMENSIONI FISSE PER L'ASCISSA\n",
    "    ax1.axvline(mean_snr, color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Media: {mean_snr:.2f} dB')\n",
    "    ax1.set_title('Distribuzione SNR Predicted vs Clean')\n",
    "    ax1.set_xlabel('SNR (dB)')\n",
    "    ax1.set_ylabel('Frequenza')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribuzione miglioramenti\n",
    "    ax2.hist(snr_improvements, bins=40, alpha=0.7, color='green', edgecolor='darkgreen')\n",
    "    mean_imp = np.mean(snr_improvements)\n",
    "    ax2.axvline(mean_imp, color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Media: {mean_imp:.2f} dB')\n",
    "    ax2.axvline(0, color='black', linestyle='-', alpha=0.5, label='No improvement')\n",
    "    ax2.set_title('Distribuzione SNR Improvements')\n",
    "    ax2.set_xlabel('SNR Improvement (dB)')\n",
    "    ax2.set_ylabel('Frequenza')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva il grafico\n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(exist_ok=True)\n",
    "    plot_file = save_path / 'snr_distributions.png'\n",
    "    plt.savefig(plot_file, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return str(plot_file)\n",
    "\n",
    "def main(save_audio_samples=None, plot_samples=None):\n",
    "    \"\"\"Funzione principale - specifica save_audio_samples=[1,5,10] per salvare audio\"\"\"\n",
    "    \n",
    "    # Inizializza componenti\n",
    "    audio_processor = AudioProcessor(n_fft, n_fft, SAMPLE_RATE)\n",
    "    plotter = SingleSamplePlotter(SAMPLE_RATE)\n",
    "    snr_calculator = SNRCalculator()\n",
    "    \n",
    "    # Carica modello\n",
    "    print(\" Caricamento modello...\")\n",
    "    model = DCUnet20(n_fft=n_fft, hop_length=n_fft).to(device)\n",
    "    model.load_state_dict(torch.load(\"/kaggle/input/pretrainedweights/Pretrained_Weights/Noise2Noise/white.pth\", \n",
    "                                   map_location=device))\n",
    "    \n",
    "    print(f\" Setup completato - Device: {device}\")\n",
    "    \n",
    "    # Valutazione\n",
    "    snr_values, snr_improvements, ssnr_values, ssnr_improvements = evaluate_testset(\n",
    "        model=model,\n",
    "        test_loader=test_loader_single_unshuffled,\n",
    "        audio_processor=audio_processor,\n",
    "        snr_calculator=snr_calculator,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        save_audio_for=save_audio_samples,\n",
    "        plot_samples=plot_samples,\n",
    "        plotter=plotter\n",
    "    )\n",
    "    \n",
    "    # Stampa risultati come nell'immagine\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" RISULTATI FINALI DEL TEST SET\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Totale campioni processati: {len(snr_values)}\")\n",
    "    print(f\"SNR medio predicted vs clean: {np.mean(snr_values):.2f} ± {np.std(snr_values):.2f} dB\")\n",
    "    print(f\"SNR improvement medio: {np.mean(snr_improvements):.2f} ± {np.std(snr_improvements):.2f} dB\")\n",
    "    print(f\"SNR minimo: {np.min(snr_values):.2f} dB\")\n",
    "    print(f\"SNR massimo: {np.max(snr_values):.2f} dB\")\n",
    "    print(f\"Mediana SNR: {np.median(snr_values):.2f} dB\")\n",
    "\n",
    "    print(f\"SSNR medio predicted vs clean: {np.mean(ssnr_values):.2f} ± {np.std(ssnr_values):.2f} dB\")\n",
    "    print(f\"SSNR improvement medio: {np.mean(ssnr_improvements):.2f} ± {np.std(ssnr_improvements):.2f} dB\")\n",
    "\n",
    "    \n",
    "    improvement_rate = (sum(1 for x in snr_improvements if x > 0) / len(snr_improvements)) * 100\n",
    "    print(f\"Campioni con miglioramento: {sum(1 for x in snr_improvements if x > 0)}/{len(snr_improvements)} ({improvement_rate:.1f}%)\")\n",
    "    \n",
    "    # Crea grafici\n",
    "    plot_file = plot_results(snr_values, snr_improvements)\n",
    "    print(f\"\\n Grafico salvato: {plot_file}\")\n",
    "    \n",
    "    return snr_values, snr_improvements\n",
    "\n",
    "# ESECUZIONE\n",
    "# Per salvare audio di campioni specifici, usa:\n",
    "# results = main(save_audio_samples=[1, 5, 10])  # salva audio dei campioni 1, 5 e 10\n",
    "# \n",
    "# Per non salvare audio:\n",
    "# results = main()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cambia qui i numeri dei campioni di cui vuoi salvare l'audio\n",
    "    SAMPLES_TO_SAVE_AND_PLOT = [1, 3, 10]  # Modifica con i numeri che preferisci\n",
    "    \n",
    "    print(\" Avvio valutazione...\")\n",
    "    results = main(save_audio_samples=SAMPLES_TO_SAVE_AND_PLOT, plot_samples=SAMPLES_TO_SAVE_AND_PLOT)\n",
    "    print(\" Valutazione completata!\")\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7846568,
     "sourceId": 12439163,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 43112.702824,
   "end_time": "2025-08-12T05:49:47.528260",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-11T17:51:14.825436",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
