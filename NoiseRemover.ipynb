{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frads01/NoiseRemover/blob/main/NoiseRemover.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noise Remover\n"
      ],
      "metadata": {
        "id": "OYfLqR29sPnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indicazione Path per i dati di input e target:"
      ],
      "metadata": {
        "id": "Tvl_FjKEC-6F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG7bdC-hsKtv"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "TRAIN_INPUT_DIR = Path('Datasets/Train_Input')\n",
        "TRAIN_TARGET_DIR = Path('Datasets/Train_Output')\n",
        "\n",
        "#TEST_NOISY_DIR = Path('Datasets/Test_Input')\n",
        "#TEST_CLEAN_DIR = Path('Datasets/clean_testset_wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import librerie:"
      ],
      "metadata": {
        "id": "RisdxjMgEB7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "#determinismo CUDA GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "yycpjxF9EEkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parametri per la trasformazione STFT:"
      ],
      "metadata": {
        "id": "46TSDkqFEuKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_fft = 2048 #grandezza della finestra (risoluzione in frequenza) - nel paper è 3072, ottima per il parlato\n",
        "hop_length = 512 #salto tra una finestra e l’altra (risoluzione temporale) - nel paper è 768"
      ],
      "metadata": {
        "id": "BdHJ8JPvEzOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dichiarazioni del Dataset e del Dataloader:"
      ],
      "metadata": {
        "id": "x8EeJlBLJm2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Noise2NoiseDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset per training Noise2Noise su audio.\n",
        "    Ogni esempio ha due versioni rumorose dello stesso contenuto.\n",
        "    \"\"\"\n",
        "    def __init__(self, noisy_file_set_A, noisy_file_set_B, n_fft=2048, hop_length=512):\n",
        "        super().__init__()\n",
        "        self.noisy_A = sorted(noisy_file_set_A)\n",
        "        self.noisy_B = sorted(noisy_file_set_B)\n",
        "\n",
        "        assert len(self.noisy_A) == len(self.noisy_B), \"Le due liste devono avere la stessa lunghezza.\"\n",
        "\n",
        "        self.n_fft = n_fft\n",
        "        self.hop_length = hop_length\n",
        "        self.max_len = 165000  # puoi regolarla\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.noisy_A)\n",
        "\n",
        "    def load_sample(self, file):\n",
        "        waveform, _ = torchaudio.load(file)\n",
        "        return waveform\n",
        "\n",
        "    def _prepare_sample(self, waveform):\n",
        "        \"\"\"Pad o tronca a self.max_len campioni, da sinistra o destra.\"\"\"\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform[:1, :]  # prendi solo 1 canale\n",
        "\n",
        "        current_len = waveform.shape[1]\n",
        "\n",
        "        if current_len >= self.max_len:\n",
        "            waveform = waveform[:, :self.max_len]\n",
        "        else:\n",
        "            pad_len = self.max_len - current_len\n",
        "            waveform = torch.nn.functional.pad(waveform, (0, pad_len), mode='constant', value=0.0)\n",
        "\n",
        "        return waveform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # carica audio\n",
        "        x1 = self.load_sample(self.noisy_A[index])\n",
        "        x2 = self.load_sample(self.noisy_B[index])\n",
        "\n",
        "        # padding/troncamento\n",
        "        x1 = self._prepare_sample(x1)\n",
        "        x2 = self._prepare_sample(x2)\n",
        "\n",
        "        # STFT\n",
        "        x1_stft = torch.stft(x1, n_fft=self.n_fft, hop_length=self.hop_length, normalized=True, return_complex=True)\n",
        "        x2_stft = torch.stft(x2, n_fft=self.n_fft, hop_length=self.hop_length, normalized=True, return_complex=True)\n",
        "\n",
        "        return x1_stft, x2_stft\n",
        "\n",
        "    files_noise_input = sorted(list(PATH_TO_NOISE_VERSION_1.rglob(\"*.wav\")))\n",
        "    files_noise_target = sorted(list(PATH_TO_NOISE_VERSION_2.rglob(\"*.wav\")))\n",
        "    #test_noisy_files = sorted(list(TEST_NOISY_DIR.rglob('*.wav')))\n",
        "    #test_clean_files = sorted(list(TEST_CLEAN_DIR.rglob('*.wav')))\n",
        "\n",
        "    print(\"No. of Training files:\",len(files_noise_input))\n",
        "    #print(\"No. of Testing files:\",len(test_noisy_files))\n",
        "\n",
        "    noise2noise_dataset = Noise2NoiseDataset(files_noise_input, files_noise_target, n_fft=1024, hop_length=256)\n",
        "    train_loader = DataLoader(noise2noise_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "    # For testing purpose\n",
        "    #test_loader_single_unshuffled = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "QYHVs_vnJrGl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}